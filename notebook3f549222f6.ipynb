{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e2f9897fc3d95962eb576448d828375d0c3922a3"
   },
   "source": [
    "# Time Series Analysis and forecasting using ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92be38e2a9eb90c82736818f9a6e7b289b9a4cfd"
   },
   "source": [
    "## What is a time series problem\n",
    "In the field for machine learning and data science, most of the real-life problems are based upon the prediction of future which is totally oblivious to us such as stock market prediction, future sales prediction and so on.Time series problem is basically the prediction of such problems using various machine learning tools.Time series problem is tackled efficiently when first it is analyzed properly (Time Series Analysis) and according to that observation suitable algorithm is used (Time Series Forecasting).We'll study both of then later in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "df = pd.read_csv(\"../input/portland-oregon-average-monthly-.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "828eb5918a272230c1735b3d0195db5e8056afcf"
   },
   "outputs": [],
   "source": [
    "# A glance on the data \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "835be2a74f99fce4afe24478038a41eb59d6c8c1"
   },
   "outputs": [],
   "source": [
    "# getting some information about dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c5dab9fa80f6d0a781f5828f442a4547b524ba0"
   },
   "source": [
    "From this I can infer two necessary things:\n",
    "1. I really need to change change columns name\n",
    "2. Both the columns have object datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "fb46c093da662005ca81d3734697e867c506685c"
   },
   "outputs": [],
   "source": [
    "# further Analysis \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "bd3acad0ad3863a1900fd02fbd580aebd005df3e"
   },
   "outputs": [],
   "source": [
    "df.columns = [\"month\", \"average_monthly_ridership\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "60582b6176f4ab4d4a49e3054f34beb3da11cd04"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "0671ea9c4ea0029308c460390db40467bfd6e16f"
   },
   "outputs": [],
   "source": [
    "df['average_monthly_ridership'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2a4a4908fd57904eedacda359e7deafd8302bff0"
   },
   "source": [
    "We can see here that this series consist an anamolous data which is the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "f9047c26b8e0024a2b735dfe09cb1c559eb990f4",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(df.index[df['average_monthly_ridership'] == ' n=114'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "6da2043868e71a1d0971645989f9c4a7ed46b38a"
   },
   "outputs": [],
   "source": [
    "df['average_monthly_ridership'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3339f16b5d0983f7e3bcc12b20e3cafb6ad9f305"
   },
   "source": [
    "Now our data is clean !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "363289a42ab27d847f69570f836e00bee7ec7b18"
   },
   "source": [
    "Changing data type of both the column\n",
    "* Assign int to ```monthly_ridership_data``` column\n",
    "* Assign datetime to ```month``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "50cb6803cfc1a6f5aff20ecf0f7c6ef719d113a6",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df['average_monthly_ridership'] = df['average_monthly_ridership'].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "9427ddd6d60fd2a7011e0848b47d9970cf4c0a04",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df['month'] = pd.to_datetime(df['month'], format = '%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "655a033716107144447aafb866746906b608cb71"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61a0a416983614dfbced580e700140909c3d316f"
   },
   "source": [
    "# Time Series Analysis\n",
    "\n",
    "As you all know how important data analysis is for data scientists.It gives us a brief understanding of the data and a very strange but intriguing confidence about our prediction model.Well, Time series analysis is no different.But time series problems have very special orientation when it comes to analysis.But before we move into that, let me introduce you to some jargons (Just Kidding it is pure and simple english) which are frequently used in this problem domain.\n",
    "\n",
    "**Trend**:- As the name suggests trend depicts the variation in the output as time increases.It is often non-linear. Sometimes we will refer to trend as “changing direction” when it might go from an increasing trend to a decreasing trend.\n",
    "\n",
    "**Level**:- It basically depicts baseline value for the time series.\n",
    "\n",
    "**Seasonal**:- As its name depicts it shows the repeated pattern over time. In layman terms, it shows the seasonal variation of data over time.\n",
    "\n",
    "**Noise**:- It is basically external noises that vary the data randomly.\n",
    "\n",
    "You can see below various graphs I plotted and what I inferred from them. which is totally oblivious to us such as stock market prediction, future sales prediction and so on.Time series problem is basically the prediction of such problems using various machine learning tools.Time series problem is tackled efficiently when first it is analyzed properly (Time Series Analysis) and according to that observation suitable algorithm is used (Time Series Forecasting).We'll study both of then later in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "3ef285f1b78b798ae9766ee6bdf71bf84d495c86"
   },
   "outputs": [],
   "source": [
    "# Normal line plot so that we can see data variation\n",
    "# We can observe that average number of riders is increasing most of the time\n",
    "# We'll later see decomposed analysis of that curve\n",
    "df.plot.line(x = 'month', y = 'average_monthly_ridership')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "acc8482afff4dc21829660b7a155b86b9c0b1bd6"
   },
   "source": [
    "## Ploting monthly variation of dataset\n",
    "It gives us idea about seasonal variation of our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "408c45186e9d6f299044a3c51a76affe71c46a4c",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "to_plot_monthly_variation = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "a7bc08f31ed151a6d626e3c6eef56dea41764e50",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# only storing month for each index \n",
    "mon = df['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "67aac61723ff6fd8d1e332f6b8b56e45fdaa2850",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# decompose yyyy-mm data-type \n",
    "temp= pd.DatetimeIndex(mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "edce46de2d41c3a7266b6282342b105a26de5bbf",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# assign month part of that data to ```month``` variable\n",
    "month = pd.Series(temp.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "db4bb5e60a1ad819bb733f9e6b0ab8b1c8d18cd0",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# dropping month from to_plot_monthly_variation\n",
    "to_plot_monthly_variation = to_plot_monthly_variation.drop(['month'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "685233a2072c54939bfb86ce221cb594de330b24",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# join months so we can get month to average monthly rider mapping\n",
    "to_plot_monthly_variation = to_plot_monthly_variation.join(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "41f842cfb118c854550ce95b187cb8faea51def1"
   },
   "outputs": [],
   "source": [
    "# A quick glance\n",
    "to_plot_monthly_variation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "b9f78a6b09cff12daa090839b53c2631b34ac83f"
   },
   "outputs": [],
   "source": [
    "# Plotting bar plot for each month\n",
    "sns.barplot(x = 'month', y = 'average_monthly_ridership', data = to_plot_monthly_variation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a97f3f18482bade86fc38d8777193e684fa72615"
   },
   "source": [
    "Well this looks tough to decode. Not a typical box plot. One can infer that data is too sparse for this graph to represent any pattern. Hence it  cannot represents monthly variation effectively.In such a scenerio we can use our traditional scatter plot to understand pattern in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "7ec16cd40f9a357f2c97b52abe4f53261010f3a6"
   },
   "outputs": [],
   "source": [
    "to_plot_monthly_variation.plot.scatter(x = 'month', y = 'average_monthly_ridership')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e4d519dbf5d0fcaf67b56af4b0b63182dd8be782"
   },
   "source": [
    "We can see here the yearly variation of data in this plot. To understand this curve more effectively first look at the every row from bottom to top and see each year's variation.To understand yearly variation take a look at each column representing a  month.\n",
    "\n",
    "Another tool to visualize the data is the seasonal_decompose function in statsmodel. With this, the trend and seasonality become even more obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "17a8118b03025f6bb064527f4dc85dfe6eccbd88",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rider = df[['average_monthly_ridership']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dce2c1fe92777ece04a36a8c8b714c5adf47b96f"
   },
   "source": [
    "## Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "e65047709f1bffd691f74081cc3a233f554af4a3"
   },
   "outputs": [],
   "source": [
    "rider.rolling(6).mean().plot(figsize=(20,10), linewidth=5, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "45046d92b3935f86978b6faf5dbeebe2d2f12512"
   },
   "source": [
    "For trend analysis, we use smoothing techniques. In statistics smoothing a data set means to create an approximating function that attempts to capture important patterns in the data, while leaving out noise or other fine-scale structures/rapid phenomena. In smoothing, the data points of a signal are modified so individual points (presumably because of noise) are reduced, and points that are lower than the adjacent points are increased leading to a smoother signal.We implement smoothing by taking moving averages. [Exponential moving average](https://www.investopedia.com/terms/e/ema.asp) is frequently used to compute smoothed function.Here I used the rolling method which is inbuilt in pandas and frequently used for smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bbd1b40c48bd85414ae4adc73157d4bc07653018"
   },
   "source": [
    "## Seasonability Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d9c7e9fd9075638a124b414b2d1b0803063ae83c"
   },
   "source": [
    "Two most famous seasonability analysis algorithms are:-\n",
    "## [Using 1st discrete difference of object](https://machinelearningmastery.com/difference-time-series-dataset-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "79f1598cd92e94da40ea20f077ef774a5ec2c6fd"
   },
   "outputs": [],
   "source": [
    "rider.diff(periods=4).plot(figsize=(20,10), linewidth=5, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01e7a277f2fa9cf0af3801d16c4c3b80a09e069f"
   },
   "source": [
    "The above figure represents difference between average rider of a month and 4 months before that month i.e\n",
    "\n",
    "> $d[month] = a[month] - a[month - periods]$.\n",
    "\n",
    "This gives us idea about variation of data for a period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2958077eb2898611a9bdb6d786502c309890f178"
   },
   "source": [
    "## [Periodicity and Autocorrelation](https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/)\n",
    "\n",
    "Auto correlation is the most famous way to understand seasonal variation till now. We can calculate the correlation for time series observations with observations with previous time steps, called lags. Because the correlation of the time series observations is calculated with values of the same series at previous times, this is called a serial correlation, or an autocorrelation.In this plot vertical axis is represented by the following equations:-\n",
    "\n",
    "> $C_n = \\sum_{t = 1}^{n - h} (y(t) - \\hat{y}) (y(t + n) - \\hat{y}) / n$\n",
    "\n",
    "> $C_0 = \\sum_{t = 1}^{n} (y(t) - \\hat{y})^2 / n$\n",
    "\n",
    "Horizontal axis represents time lag(previous time steps)  h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "7dbd0b9fed823b716a1bae55527f7e38ac6ec07f"
   },
   "outputs": [],
   "source": [
    "pd.plotting.autocorrelation_plot(df['average_monthly_ridership'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "cf00a320f1aa026e01c164bd9e461051f4f6ad29"
   },
   "outputs": [],
   "source": [
    "pd.plotting.lag_plot(df['average_monthly_ridership'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a47b132f697d4739a66a13da4d498e030513a8d"
   },
   "source": [
    "The above curve represents the relation between current time stepp and its previous time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "689ba067663a05227db369409fe5fe51bc858987",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = df.set_index('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "f01354dba60e8d0fd01ea4d7a213a66238b1aa85"
   },
   "outputs": [],
   "source": [
    "# Applying Seasonal ARIMA model to forcast the data \n",
    "mod = sm.tsa.SARIMAX(df['average_monthly_ridership'], trend='n', order=(0,1,0), seasonal_order=(1,1,1,12))\n",
    "results = mod.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33f2b40b0fd8adb7e0e028390dfa18e9f1cc5a47"
   },
   "source": [
    "## To check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_uuid": "a3638af48819a34c78a647e95e0c8d30b460adc7"
   },
   "outputs": [],
   "source": [
    "df['forecast'] = results.predict(start = 102, end= 120, dynamic= True)  \n",
    "df[['average_monthly_ridership', 'forecast']].plot(figsize=(12, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e3fcaebc331b3432378c59bd451740929c429e8e"
   },
   "source": [
    "## To generate future forcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_uuid": "7d027f06eaecb86a0b7956b2ade827c87ec0f0ab",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def forcasting_future_months(df, no_of_months):\n",
    "    df_perdict = df.reset_index()\n",
    "    mon = df_perdict['month']\n",
    "    mon = mon + pd.DateOffset(months = no_of_months)\n",
    "    future_dates = mon[-no_of_months -1:]\n",
    "    df_perdict = df_perdict.set_index('month')\n",
    "    future = pd.DataFrame(index=future_dates, columns= df_perdict.columns)\n",
    "    df_perdict = pd.concat([df_perdict, future])\n",
    "    df_perdict['forecast'] = results.predict(start = 114, end = 125, dynamic= True)  \n",
    "    df_perdict[['average_monthly_ridership', 'forecast']].iloc[-no_of_months - 12:].plot(figsize=(12, 8))\n",
    "    plt.show()\n",
    "    return df_perdict[-no_of_months:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_uuid": "c7f53c9cccacc67c52b8ad3410f331fc0dbdcdce"
   },
   "outputs": [],
   "source": [
    "predicted = forcasting_future_months(df,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_uuid": "20200fa9593f5b791162857c35b6db34bcc33b7b"
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7950ae36a254b450fc7438a222b3eca5a47c6d19"
   },
   "source": [
    "### References:-\n",
    "1. [Deep dive into time series Analysis](http://www.statsoft.com/Textbook/Time-Series-Analysis#trend)\n",
    "2. [A Gentle Introduction to Autocorrelation and Partial Autocorrelation](https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/)\n",
    "3. [Time Series Data Visualization with Python](https://machinelearningmastery.com/time-series-data-visualization-with-python/)\n",
    "4. [Time Series Analysis Tutorial with Python](https://www.datacamp.com/community/tutorials/time-series-analysis-tutorial)\n",
    "5. [Seasonal ARIMA with Python](http://www.seanabu.com/2016/03/22/time-series-seasonal-ARIMA-model-in-python/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d59b49641680c185a1ea76a72ee74c9eb55bc69a"
   },
   "source": [
    "### Data set source\n",
    "[Portland Oregon average monthly bus ridership](https://datamarket.com/data/set/22w6/portland-oregon-average-monthly-bus-ridership-100-january-1973-through-june-1982-n114#!ds=22w6&display=line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4bad0447c22319862a61eb4fc7a7997dbc6fdb3e"
   },
   "source": [
    "Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4cf13a0f6867b8da533a26f2804c86fe0bd57cf2",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
